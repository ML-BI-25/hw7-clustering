{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0ed061b8",
   "metadata": {},
   "source": [
    "# Домашнее задание №7 - Кластеризация\n",
    "\n",
    "На этой неделе мы реализуем свою версию алгоритма K-Means, опробуем иерархическую кластеризацию, а также еще раз глянем задачу с клеточными типами на основе данных цитометрии."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bec6c7e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from os.path import join\n",
    "from IPython import display\n",
    "from sklearn.datasets import load_digits\n",
    "from sklearn.datasets import make_blobs\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.metrics import silhouette_score # и другие метрики\n",
    "from sklearn.cluster import KMeans # а также другие алгоритмы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d1495a6-f860-452e-a2ca-034ecdb853bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = \"data\"\n",
    "plt.rcParams[\"figure.figsize\"] = 12, 9\n",
    "sns.set_style(\"whitegrid\")\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "SEED = 111\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bc8de22-340d-4a2e-a88f-927770111be1",
   "metadata": {},
   "source": [
    "## Задание 1. Реализация K-means\n",
    "\n",
    "**60 баллов**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2554377b-7fa9-4198-888c-47d1c37f5283",
   "metadata": {},
   "source": [
    "В данном задании вам предстоит дописать код класса `MyKMeans`. Мы на простом примере увидим, как подбираются центры кластеров и научимся их визуализировать."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1018a29-7e2a-4041-8e8b-c871668ec7fa",
   "metadata": {},
   "source": [
    "(5 баллов) Сгенерируем простой набор данных, 400 объектов и 2 признака (чтобы все быстро работало и можно было легко нарисовать):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7fc05e1-c5ff-4c15-af0e-079833e1413d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, true_labels = make_blobs(400, 2, centers=[[0, 0], [-4, 0], [3.5, 3.5], [3.5, -2.0]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb54d1c6-a093-40b5-acaa-042b15afb9e1",
   "metadata": {},
   "source": [
    "Используем функцию `visualize_clusters`, которая по данным и меткам кластеров будет рисовать их и разукрашивать:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25de72de-5fd0-408b-88f2-3b7325c4dbc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_clusters(X, labels):\n",
    "    \"\"\"\n",
    "    Функция для визуализации кластеров\n",
    "        :param X: таблица объекты х признаки\n",
    "        :param labels: np.array[n_samples] - номера кластеров\n",
    "    \"\"\"\n",
    "    \n",
    "    unique_labels = np.sort(np.unique(labels))\n",
    "    sns.scatterplot(x=X[:, 0], y=X[:, 1], hue=labels, \n",
    "                    palette=\"colorblind\", legend=False,\n",
    "                    hue_order=unique_labels)\n",
    "    plt.xlabel(\"$X_1$\", fontsize=18)\n",
    "    plt.ylabel(\"$X_2$\", fontsize=18)\n",
    "    \n",
    "    for label in labels:\n",
    "        center = X[(labels == label)].mean(axis=0)\n",
    "        plt.scatter(center[0], center[1], s=80, c=\"#201F12\", marker=(5, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d633f931-dd91-4406-84e5-8c0c610cdad4",
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_clusters(X, true_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1d79024-9510-4e1d-9cf8-9c8f99317cd7",
   "metadata": {},
   "source": [
    "(40 баллов) Напишем свой класс `MyKMeans`, который будет реализовывать алгоритм кластеризации K-средних. Напомним сам алгоритм:\n",
    "\n",
    "1. Выбераем число кластеров (K)\n",
    "2. Случайно инициализируем K точек (или выбираем из данных), это будут начальные центры наших кластеров\n",
    "3. Далее для каждого объекта считаем расстояние до всех кластеров и присваиваем ему метку ближайщего\n",
    "4. Далее для каждого кластера считаем \"центр масс\" (среднее значение для каждого признака по всем объектам кластера)\n",
    "5. Этот \"центр масс\" становится новым центром кластера\n",
    "6. Повторяем п.3, 4, 5 заданное число итераций или до сходимости\n",
    "\n",
    "Во время предсказания алгоритм просто находит ближайщий центроид (центр кластера) для тестового объекта и возвращает его номер."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bea2fc4-ba1f-41f0-9969-f9e6d7d7d796",
   "metadata": {},
   "source": [
    "Реализуйте методы:\n",
    "* `_calculate_distance(X, centroid)` - вычисляет Евклидово расстояние от всех объектов в `Х` до заданного центра кластера (`centroid`)\n",
    "* `predict(X)` - для каждого элемента из `X` возвращает номер кластера, к которому относится данный элемент"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1037858c-086a-47b7-8786-f5750569edd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyKMeans:\n",
    "    def __init__(self, n_clusters, init=\"random\", max_iter=300, visualize=False):\n",
    "        \"\"\"\n",
    "        Конструктор класса MyKMeans\n",
    "            :param n_clusters: число кластеров\n",
    "            :param init: способ инициализации центров кластеров\n",
    "                'random' - генерирует координаты случайно из нормального распределения\n",
    "                'sample' - выбирает центроиды случайно из объектов выборки\n",
    "            :param max_iter: заданное число итераций \n",
    "                (мы не будем реализовывать другой критерий остановки)\n",
    "            :param visualize: рисовать ли кластеры и их центроиды в процессе работы\n",
    "                код будет работать сильно дольше, но красиво...\n",
    "        \"\"\"\n",
    "        \n",
    "        assert init in [\"random\", \"sample\"], f\"Неизвестный метод инициализации {init}\"\n",
    "        self.n_clusters = n_clusters\n",
    "        self.init = init\n",
    "        self.max_iter = max_iter\n",
    "        self.centroids = None\n",
    "        self.visualize = visualize\n",
    "       \n",
    "    \n",
    "    def fit(self, X):\n",
    "        \"\"\"\n",
    "        Подбирает оптимальные центры кластеров\n",
    "            :param X: наши данные (n_samples, n_features)\n",
    "        :return self: все как в sklearn\n",
    "        \"\"\"\n",
    "        \n",
    "        n_samples, n_features = X.shape\n",
    "        \n",
    "        # Инициализация центров кластеров\n",
    "        if self.init == \"random\":\n",
    "            centroids = np.random.randn(self.n_clusters, n_features)\n",
    "        elif self.init == \"sample\":\n",
    "            centroids_idx = np.random.choice(np.arange(n_samples), \n",
    "                                             size=self.n_clusters, \n",
    "                                             replace=False)\n",
    "            centroids = X[centroids_idx]\n",
    "        \n",
    "        # Итеративно двигаем центры\n",
    "        for _ in range(self.max_iter):\n",
    "            # Посчитаем расстояния для всех объектов до каждого центроида\n",
    "            dists = []\n",
    "            for centroid in centroids:\n",
    "                dists.append(self._calculate_distance(X, centroid))\n",
    "            dists = np.concatenate(dists, axis=1)\n",
    "            # Для каждого объекта найдем, к какому центроиду он ближе\n",
    "            cluster_labels = np.argmin(dists, axis=1)\n",
    "            \n",
    "            # Пересчитаем центр масс для каждого кластера\n",
    "            centroids = []\n",
    "            for label in np.sort(np.unique(cluster_labels)):\n",
    "                center = X[(cluster_labels == label)].mean(axis=0)\n",
    "                centroids.append(center)\n",
    "            \n",
    "            # Отрисуем точки, покрасим по меткам кластера, а также изобразим центроиды\n",
    "            if self.visualize:\n",
    "                visualize_clusters(X, cluster_labels)\n",
    "                display.clear_output(wait=True)\n",
    "                display.display(plt.gcf())\n",
    "                plt.close()\n",
    "                \n",
    "        self.centroids = np.array(centroids)\n",
    "        \n",
    "        return self\n",
    "    \n",
    "    \n",
    "    def predict(self, X):\n",
    "        \"\"\"\n",
    "        Для каждого X возвращает номер кластера, к которому он относится\n",
    "            :param X: наши данные (n_samples, n_features)\n",
    "        :return cluster_labels: метки кластеров\n",
    "        \"\"\"\n",
    "        \n",
    "        \"\"\"\n",
    "        YOUR CODE IS HERE\n",
    "        \"\"\"\n",
    "        cluster_labels = None\n",
    "            \n",
    "        return cluster_labels\n",
    "        \n",
    "        \n",
    "    def _calculate_distance(self, X, centroid):\n",
    "        \"\"\"\n",
    "        Вычисляет Евклидово расстояние от всех объектов в Х до заданного центра кластера (centroid)\n",
    "            :param X: наши данные (n_samples, n_features)\n",
    "            :param centroid: координаты центра кластера\n",
    "        :return dist: расстояния от всех X до центра кластера\n",
    "        \"\"\"\n",
    "        \n",
    "        \"\"\"\n",
    "        YOUR CODE IS HERE\n",
    "        \"\"\"\n",
    "        dist = None\n",
    "        \n",
    "        return dist\n",
    "    \n",
    "    \n",
    "    def __repr__(self):\n",
    "        return f\"Привет, я твой KMeans (/¯◡ ‿ ◡)/¯☆*\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29842c6f-0db4-4fa9-b7e1-5ccb944b9864",
   "metadata": {},
   "source": [
    "Обучите `MyKMeans` на наших игручешных данных, добейтесь сходимости. Не забудьте поставить `visualize=True`, чтобы посмотреть на красивые картинки. (5 баллов)\n",
    "\n",
    "Также попробуйте различные способы инициализации центроидов и скажите, какой лучше подошел в этой ситуации? (10 баллов)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81c005e8-2372-45ad-aefa-e7fa41b32b30",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "788a9e3e-461a-413b-84a5-4740387ff1f0",
   "metadata": {},
   "source": [
    "## Задание 2. Подбираем лучшую кластеризацию\n",
    "\n",
    "**60 баллов**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9147a0bb-39dc-452d-bfec-d4949af87ab2",
   "metadata": {},
   "source": [
    "Во 2 и 3 части домашки вам предстоит поработать с данными, котовые вы использовали в ДЗ2. \n",
    "Возьмите уже предобработанный вариант из ДЗ2 и загрузите его здесь."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "445d787b-2934-4aaa-8a5c-9e50dd1c4344",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = # your preprocessed data from hw2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89fc5e02-7d4c-4df0-83c6-2d7f148b461d",
   "metadata": {},
   "source": [
    "На лекции были рассмотрены разлинчеы алгоритмы кластеризации. Возьмите три из них (например, `KMeans`, `DBScan` и `AgglomerativeClustering`) и попробуйте понять, какой из алгоритмов будет работать лучше на ваших данных. \n",
    "\n",
    "(30 баллов) Для каждого из алгоритмов выберите несколько значений самых важных параметров (не забудьте описать, что за параметры вы выбрали и что они значат в конкретном алгоритме) и посчитайте для них значения `Silhouette` коэффициента. Сначала сделайте это внутри каждого алгоритма, отобрав лучшие гиперпараметры внутри каждого алгоритма. Постройте графики изменения значений силуэта в зависимости от значения параметра и выберите лучший вариант.\n",
    "\n",
    "(20 баллов) В итоге у вас получится три лучших модели (по одной на каждый алгоритм). Для этих моделей перейдите к сравнению алгоритмов между собой. Сравнение между лучшими проведите при помощи отрисовки `Silhouette plot`, опишите получившиеся результаты и выберите финальный вариант.\n",
    "\n",
    "(10 баллов) Возьмите любой метод уменьшения размерности (опять же, можете брать тот который на 2дз лучше всего работал или вообще любой) и визуализируйте ваши данные с покраской по лэйблам лучшего алгоритма."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16323581-d0cf-4e6a-9319-78a02aaad4d3",
   "metadata": {},
   "source": [
    "##### YOUR TURN TO CODE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1010717d-e93c-4f2a-a371-ee60d1f295cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "## ENTER YOUR CODE HERE (/¯◡ ‿ ◡)/¯☆*##"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "608ce824-846f-4e66-9557-bbc67c25ffc7",
   "metadata": {},
   "source": [
    "## Задание 3. Рисуем кластермапу\n",
    "\n",
    "**30 баллов + доп 10 баллов**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "019c3642-97c9-4ec2-9bc0-2d87ed5012e9",
   "metadata": {},
   "source": [
    "Мы также отдельно обсуждали с вами, что есть такая классная вещь как `clustermap`. \n",
    "\n",
    "Возьмите ваши исходные данные, отберите из них примерно 50 случайных строк, и отрисуйте `clustermap` для них. Посмотрите на разные метрики расстояния для `clustermap`, попробуйте увидеть какие метрики работают лучше/хуже на вашем датасете (тут просто нарисуйте и посмотрите на дендрограммы по фичам/образцам, сделайте выводы).  \n",
    "\n",
    "(*доп*) Возьмите метки клеточных типов, которые получались у вас во второй домашке. Используя эти метки сделайте кластермапу с покраской строк по их клеточным типам (тут можно использовать уже все данные). Делается это в seaborn при помощи параметра `row_colors`, не забудьте добавить легенду к вашей визуализации, в которой будет понятно к какому цвету относится тот или иной клеточный тип."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "682d28ff-4863-467b-b059-6eb8c8d42700",
   "metadata": {},
   "outputs": [],
   "source": [
    "## ENTER YOUR CODE HERE (/¯◡ ‿ ◡)/¯☆*##"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a875a4e9",
   "metadata": {},
   "source": [
    "**Ваш комментарий к результатам:**\n",
    "\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "824b9905-57ad-4206-a6dc-a606bebf0d29",
   "metadata": {},
   "source": [
    "На этой неделе кидаю вам мемчик про хитмапы.\n",
    "С вас тоже что-нибудь забавное:)\n",
    "\n",
    "Ура, последняя домашка первой части курса сделана! От всей команды поздравляю вас, вы игромные умнички! Было очень классно:)\n",
    "\n",
    "![pic](https://i.imgflip.com/4wa3y8.jpg)\n",
    "\n",
    "**Ваши мысли:**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7be3924",
   "metadata": {},
   "source": [
    "### Therapy time\n",
    "\n",
    "Напишите здесь ваши впечатления о задании: было ли интересно, было ли слишком легко или наоборот сложно и тд. Также сюда можно написать свои идеи по улучшению заданий, а также предложить данные, на основе которых вы бы хотели построить следующие дз."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be779c8c-0a1f-4cb9-8f7e-c9bf2fcc2dff",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
